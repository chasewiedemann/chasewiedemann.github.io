---
title: "Replication"
output: html_document
---
```{r,echo = F}
base_dir = getwd()
base_url = paste0("https://",substr(base_dir,8, nchar(base_dir)))
wp_link = paste0(base_url,"/WorkingPaper.html")
ws_link = paste0(base_url,"/WorkingSlides.html")
rep_link = paste0(base_url,"/Replication.html")
miniblog_link = paste0(base_url,"/MiniBlog.html")
```

[Home](https://chasewiedemann.github.io/index.html) |
[About](https://chasewiedemann.github.io/Site/about.html) |
[Projects](https://chasewiedemann.github.io/Site/Projects/projects.html) |
[Paper Summaries](https://chasewiedemann.github.io/Site/Summaries/summaries.html) |
[Blog](https://chasewiedemann.github.io/Site/blog.html) |

[Working Paper](`r wp_link`)|
[Working Slides](`r ws_link`)|
[Replication](`r rep_link`)|
[Mini-Blog](`r miniblog_link`)|


# Introduction

When working in Urban Economics, we unsurprising focus on Urban areas. But what is an Urban area? We tend to take this as some predefined object, such as a MSA, a group of countys, or whatever level of data that we have. The goal of this paper is to let the data identify what an Urban Area should be, and really to go beyond that. 

For a long time, and still somewhat currently, the workhorse model of urban economics was the Alonzo-Mills-Muth Model of the Central Business District (CBD). What that theory says is that all urban areas are built around CBD's which are historically the major city that has been around the longest. So the St. Louis CBD would be centered by the city of St. Louis and the surrounding area would fall into the urbn area around that CBD. 

What do CBD's do? Well they produce. A standard model would have the assumption that all people living in the urban area work in the CBD. These workers can only access utility through working in the CBD (Maybe you normalize the utility of work outside the CBD to zero). A common assumption would also be that workers are symmetric, so that they all have to get the same utility. 

# Model and Identification

I think I need to be talking about the model in terms of the Census's Business Register, instead of what we observe as the zipcode. So the model is based on each firms decisions, but we only observe this statistic about the groupings in a zipcode. That should help clarify what assumptions we are making that are solely a function of not having the business registrar data.




# Data

We are going to be using the County Business Patterns Zipcode Files 1994-2022 for this project. These are basically a summary statistic of the Business Registrar at the zip code level. The Business Registrar has the data on every business that is registered with the IRS. 

As we are concerned with a timeseries, the data availability in 1994 will dictate what variables we use moving forward. We can look at the API's variables page to see what is available

```{r,eval=T}
library(kableExtra)
url = "https://api.census.gov/data/1994/zbp/variables.html"
read_html(url) %>% html_table() %>% data.frame %>% select(Name, Label) %>% kable()
```
From this, we will take Total Number of Employees, Employment Size of Establishments, Total Number of Establishments, the Geography ID, Total Annual Payroll, and the SIC Code.

These are available for every year, but we do need to take take because the SIC Codes update every few years. This is handled in the code below which scrapes from the API for each of the years. Note that I write this in a function that saves the output into a .rds file. This takes a while, so I want to be able to get at this data without needing to scrape each time. So the function call gets commented out after I have already ran it.

```{r,eval = F}
scrape_zbp = function(){
years = 1994:2018
data = c()
for (i in 1:length(years)) {
cur_year = years[i]
if (cur_year %in% 1994:1997) {
  cur_sic = "SIC"
} else if (cur_year %in% 1998:2002) {
  cur_sic = "NAICS1997"
} else if (cur_year %in% 2003:2007){
  cur_sic = "NAICS2002"
} else if (cur_year %in% 2008:2011){
  cur_sic = "NAICS2007"
} else if (cur_year %in% 2012:2016){
  cur_sic = "NAICS2012"
} else {
  cur_sic = "NAICS2017"
}

url = paste0("https://api.census.gov/data/",cur_year,"/zbp?get=EMP,EMPSZES,ESTAB,GEO_ID,PAYANN,ZIPCODE,",cur_sic,"&for=zipcode:*")
tt = read_html(url) %>% html_text() %>% strsplit(.,"\n") %>% unlist()
filename = paste0("Data/zbp",cur_year,".rds")
saveRDS(tt,filename)
}
}
scrape_zbp()
```



